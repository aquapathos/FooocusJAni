{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aquapathos/FooocusJAni/blob/main/Fooocus_onColab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Foooocus日本語化メニュー版\n",
        "\n",
        "このプログラムは次のサイトを参考にしています。\n",
        "1. [Fooocus colab](https://github.com/lllyasviel/Fooocus/blob/main/fooocus_colab.ipynb)\n",
        "2. Fooocus 日本語アニメ特化版 [j.aicu.ai/FoooC](https://j.aicu.ai/FoooC)\n",
        "\n",
        "２は１の日本語化と、アニメ用のモデル animaPencilXL_v310.safetensors 用の自動設定をダウンロードするように仕組まれたノートです。\n",
        "\n",
        "２では　pygit2==1.12.2　をインストールするようになっていますが、１に合わせて　1.15.1　としています。\n",
        "\n",
        "## 起動オプション\n",
        "\n",
        "このスクリプトでは Google Driveの マイドライブ直下「Fooocus-outputs」に画像が保存されるようになっています。\n"
      ],
      "metadata": {
        "id": "xwciD8nyDILt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "KZYJfKVuDCOM",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "c28bcf04-762d-4ed4-e825-1f71647b72f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "/content\n",
            "fatal: destination path 'Fooocus' already exists and is not an empty directory.\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 18040  100 18040    0     0  48568      0 --:--:-- --:--:-- --:--:-- 48625\n",
            "ja.json downloaded and saved to /content/Fooocus/language/ja.json\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  1403  100  1403    0     0   4225      0 --:--:-- --:--:-- --:--:--  4225\n",
            "anime.json downloaded and saved to /content/Fooocus/presets/anime.json\n",
            "/content/Fooocus\n",
            "Already up-to-date\n",
            "Update succeeded.\n",
            "[System ARGV] ['entry_with_update.py', '--preset', 'anime', '--always-high-vram', '--output-path', '/content/gdrive/MyDrive/Fooocus-outputs', '--share', '--language', 'ja']\n",
            "Python 3.10.12 (main, Sep 11 2024, 15:47:36) [GCC 11.4.0]\n",
            "Fooocus version: 2.5.5\n",
            "Loaded preset: /content/Fooocus/presets/anime.json\n",
            "Overriding config value path_outputs with /content/gdrive/MyDrive/Fooocus-outputs\n",
            "[Cleanup] Attempting to delete content of temp dir /tmp/fooocus\n",
            "[Cleanup] Cleanup successful\n",
            "Total VRAM 15102 MB, total RAM 12979 MB\n",
            "Set vram state to: HIGH_VRAM\n",
            "Always offload VRAM\n",
            "Device: cuda:0 Tesla T4 : native\n",
            "VAE dtype: torch.float32\n",
            "Using pytorch cross attention\n",
            "Refiner unloaded.\n",
            "IMPORTANT: You are using gradio version 3.41.2, however version 4.44.1 is available, please upgrade.\n",
            "--------\n",
            "Running on local URL:  http://127.0.0.1:7865\n",
            "Running on public URL: https://1cb35aaf8d3aca08c3.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
            "model_type EPS\n",
            "UNet ADM Dimension 2816\n",
            "Using pytorch attention in VAE\n",
            "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
            "Using pytorch attention in VAE\n",
            "extra {'cond_stage_model.clip_l.text_projection', 'cond_stage_model.clip_l.logit_scale'}\n",
            "left over keys: dict_keys(['cond_stage_model.clip_l.transformer.text_model.embeddings.position_ids'])\n",
            "loaded straight to GPU\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "Base model loaded: /content/Fooocus/models/checkpoints/animagine-xl-3.0.safetensors\n",
            "VAE loaded: None\n",
            "Request to load LoRAs [] for model [/content/Fooocus/models/checkpoints/animagine-xl-3.0.safetensors].\n",
            "Fooocus V2 Expansion: Vocab with 642 words.\n",
            "Fooocus Expansion engine loaded for cuda:0, use_fp16 = True.\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.71 seconds\n",
            "2024-11-10 05:34:57.310507: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-11-10 05:34:57.347056: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-11-10 05:34:57.362904: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-11-10 05:34:57.399115: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-11-10 05:34:59.117523: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Started worker with PID 48952\n",
            "App started successful. Use the app with http://127.0.0.1:7865/ or 127.0.0.1:7865 or https://1cb35aaf8d3aca08c3.gradio.live\n",
            "Enter LCM mode.\n",
            "[Fooocus] Downloading LCM components ...\n",
            "[Parameters] Adaptive CFG = 1.0\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 0.0\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.0 : 1.0 : 0.0\n",
            "[Parameters] Seed = 4632574801726992375\n",
            "[Parameters] CFG = 1.0\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = lcm - lcm\n",
            "[Parameters] Steps = 8 - 8\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "Request to load LoRAs [('sdxl_lcm_lora.safetensors', 1.0)] for model [/content/Fooocus/models/checkpoints/animagine-xl-3.0.safetensors].\n",
            "Loaded LoRA [/content/Fooocus/models/loras/sdxl_lcm_lora.safetensors] for UNet [/content/Fooocus/models/checkpoints/animagine-xl-3.0.safetensors] with 788 keys at weight 1.0.\n",
            "Requested to load SDXLClipModel\n",
            "Loading 1 new model\n",
            "unload clone 1\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.50 seconds\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] 1girl with a cat and a dog, intricate, elegant, highly detailed, wonderful colors, sweet, sharp focus, professional, charming, pretty, clear aesthetic, thought, expressive, extremely delicate, innocent, iconic, fine detail, rich deep vivid color, beautiful romantic perfect, symmetry, best, ambient light, shining, balanced, great composition, dynamic, atmosphere, lively\n",
            "[Fooocus] Preparing Fooocus text #2 ...\n",
            "[Prompt Expansion] 1girl with a cat and a dog, intricate, elegant, highly detailed, wonderful colors, glowing, sharp focus, beautiful, dramatic, full thought, professional cinematic, singular, fine detail, colorful, extremely inspirational, noble, perfect background, divine, stunning, inspiring, creative, pure, attractive, cute, best,, light, saturated color, deep aesthetic, very\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.13 seconds\n",
            "[Fooocus] Encoding positive #2 ...\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (1152, 896)\n",
            "Preparation time: 4.78 seconds\n",
            "Using sgm_uniform scheduler.\n",
            "[Fooocus] Preparing task 1/2 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.39970141649246216, sigma_max = 14.614640235900879\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.78 seconds\n",
            "100% 8/8 [00:03<00:00,  2.01it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.33 seconds\n",
            "[Fooocus] Saving image 1/2 to system ...\n",
            "Image generated with private log at: /content/gdrive/MyDrive/Fooocus-outputs/2024-11-10/log.html\n",
            "Generating and saving time: 8.85 seconds\n",
            "[Fooocus] Preparing task 2/2 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.39970141649246216, sigma_max = 14.614640235900879\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.87 seconds\n",
            "100% 8/8 [00:03<00:00,  2.33it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.31 seconds\n",
            "[Fooocus] Saving image 2/2 to system ...\n",
            "Image generated with private log at: /content/gdrive/MyDrive/Fooocus-outputs/2024-11-10/log.html\n",
            "Generating and saving time: 7.32 seconds\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 16.17 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 21.04 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.09 seconds\n",
            "Enter LCM mode.\n",
            "[Fooocus] Downloading LCM components ...\n",
            "[Parameters] Adaptive CFG = 1.0\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 0.0\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.0 : 1.0 : 0.0\n",
            "[Parameters] Seed = 3944894992603843498\n",
            "[Parameters] CFG = 1.0\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = lcm - lcm\n",
            "[Parameters] Steps = 8 - 8\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "model_type EPS\n",
            "UNet ADM Dimension 2816\n",
            "Using pytorch attention in VAE\n",
            "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
            "Using pytorch attention in VAE\n",
            "extra {'cond_stage_model.clip_l.text_projection', 'cond_stage_model.clip_l.logit_scale'}\n",
            "left over keys: dict_keys(['cond_stage_model.clip_l.transformer.text_model.embeddings.position_ids'])\n",
            "loaded straight to GPU\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 2.06 seconds\n",
            "Base model loaded: /content/Fooocus/models/checkpoints/animaPencilXL_v310.safetensors\n",
            "VAE loaded: None\n",
            "Request to load LoRAs [('sdxl_lcm_lora.safetensors', 1.0)] for model [/content/Fooocus/models/checkpoints/animaPencilXL_v310.safetensors].\n",
            "Loaded LoRA [/content/Fooocus/models/loras/sdxl_lcm_lora.safetensors] for UNet [/content/Fooocus/models/checkpoints/animaPencilXL_v310.safetensors] with 788 keys at weight 1.0.\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.20 seconds\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] 1girl with a cat and a dog, intricate, elegant, highly detailed, wonderful colors, glowing, sharp focus, colorful, great composition, dynamic light, cinematic, extremely aesthetic, very inspirational, beautiful, enhanced quality, fine detail, clear color, attractive, creative, positive, cute, artistic, fabulous, radiant, thought, iconic, shiny, awesome, bright\n",
            "[Fooocus] Preparing Fooocus text #2 ...\n",
            "[Prompt Expansion] 1girl with a cat and a dog, intricate, elegant, highly detailed, wonderful colors, cute, divine, dramatic light, sharp focus, beautiful, enhanced quality, decorative background, very detail, professional, fair, artistic, positive, pleasant, scientific, thought, ambient, inspired, extremely fine, perfect, innocent, illuminated, colorful, color, polished, complex\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.14 seconds\n",
            "[Fooocus] Encoding positive #2 ...\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (1152, 896)\n",
            "Preparation time: 53.10 seconds\n",
            "Using sgm_uniform scheduler.\n",
            "[Fooocus] Preparing task 1/2 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.39970141649246216, sigma_max = 14.614640235900879\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 2.47 seconds\n",
            "100% 8/8 [00:03<00:00,  2.36it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.28 seconds\n",
            "[Fooocus] Saving image 1/2 to system ...\n",
            "Image generated with private log at: /content/gdrive/MyDrive/Fooocus-outputs/2024-11-10/log.html\n",
            "Generating and saving time: 8.62 seconds\n",
            "[Fooocus] Preparing task 2/2 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.39970141649246216, sigma_max = 14.614640235900879\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.75 seconds\n",
            "100% 8/8 [00:03<00:00,  2.32it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.34 seconds\n",
            "[Fooocus] Saving image 2/2 to system ...\n",
            "Image generated with private log at: /content/gdrive/MyDrive/Fooocus-outputs/2024-11-10/log.html\n",
            "Generating and saving time: 7.12 seconds\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 15.73 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 68.93 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.86 seconds\n",
            "Enter LCM mode.\n",
            "[Fooocus] Downloading LCM components ...\n",
            "[Parameters] Adaptive CFG = 1.0\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 0.0\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.0 : 1.0 : 0.0\n",
            "[Parameters] Seed = 6903027957885891869\n",
            "[Parameters] CFG = 1.0\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = lcm - lcm\n",
            "[Parameters] Steps = 8 - 8\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "model_type EPS\n",
            "UNet ADM Dimension 2816\n",
            "Using pytorch attention in VAE\n",
            "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
            "Using pytorch attention in VAE\n",
            "extra {'cond_stage_model.clip_l.text_projection', 'cond_stage_model.clip_l.logit_scale'}\n",
            "left over keys: dict_keys(['cond_stage_model.clip_l.transformer.text_model.embeddings.position_ids'])\n",
            "loaded straight to GPU\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 2.48 seconds\n",
            "Base model loaded: /content/Fooocus/models/checkpoints/sd_xl_base_1.0_0.9vae.safetensors\n",
            "VAE loaded: None\n",
            "Request to load LoRAs [('sdxl_lcm_lora.safetensors', 1.0)] for model [/content/Fooocus/models/checkpoints/sd_xl_base_1.0_0.9vae.safetensors].\n",
            "Loaded LoRA [/content/Fooocus/models/loras/sdxl_lcm_lora.safetensors] for UNet [/content/Fooocus/models/checkpoints/sd_xl_base_1.0_0.9vae.safetensors] with 788 keys at weight 1.0.\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.03 seconds\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] 1girl with a cat and a dog, intricate, elegant, highly detailed, wonderful colors, sweet, sharp focus, colorful, sacred light, majestic, dramatic, thought, cinematic, pristine, beautiful, unique, illuminated, extremely emotional glowing, attractive, pretty, depicted, artistic, winning, fine detail, enhanced, perfect, color, clear, marvelous, surreal, creative\n",
            "[Fooocus] Preparing Fooocus text #2 ...\n",
            "[Prompt Expansion] 1girl with a cat and a dog, intricate, elegant, highly detailed, wonderful colors, sweet, sharp focus, dramatic, expressive, thought, fancy, extremely delicate, colorful, epic composition, brilliant, perfect cinematic color, beautiful dynamic light, attractive, very inspirational, stunning, creative, amazing, cute, surreal, iconic, fine, complex, enhanced, professional\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.13 seconds\n",
            "[Fooocus] Encoding positive #2 ...\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (1152, 896)\n",
            "Preparation time: 45.96 seconds\n",
            "Using sgm_uniform scheduler.\n",
            "[Fooocus] Preparing task 1/2 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.39970141649246216, sigma_max = 14.614640235900879\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.76 seconds\n",
            "100% 8/8 [00:03<00:00,  2.32it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.29 seconds\n",
            "[Fooocus] Saving image 1/2 to system ...\n",
            "Image generated with private log at: /content/gdrive/MyDrive/Fooocus-outputs/2024-11-10/log.html\n",
            "Generating and saving time: 8.11 seconds\n",
            "[Fooocus] Preparing task 2/2 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.39970141649246216, sigma_max = 14.614640235900879\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.85 seconds\n",
            "100% 8/8 [00:03<00:00,  2.32it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.27 seconds\n",
            "[Fooocus] Saving image 2/2 to system ...\n",
            "Image generated with private log at: /content/gdrive/MyDrive/Fooocus-outputs/2024-11-10/log.html\n",
            "Generating and saving time: 7.12 seconds\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 15.23 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 61.26 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.81 seconds\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 2199, in block_thread\n",
            "    time.sleep(0.1)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Fooocus/entry_with_update.py\", line 46, in <module>\n",
            "    from launch import *\n",
            "  File \"/content/Fooocus/launch.py\", line 152, in <module>\n",
            "    from webui import *\n",
            "  File \"/content/Fooocus/webui.py\", line 1120, in <module>\n",
            "    shared.gradio_root.launch(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 2115, in launch\n",
            "    self.block_thread()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 2203, in block_thread\n",
            "    self.server.close()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/networking.py\", line 49, in close\n",
            "    self.thread.join()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1096, in join\n",
            "    self._wait_for_tstate_lock()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1116, in _wait_for_tstate_lock\n",
            "    if lock.acquire(block, timeout):\n",
            "KeyboardInterrupt\n",
            "Killing tunnel 127.0.0.1:7865 <> https://1cb35aaf8d3aca08c3.gradio.live\n"
          ]
        }
      ],
      "source": [
        "# @markdown #Fooocus JP + Google Drive Output\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Google Driveをマウント\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "target_drive_dir = \"/content/gdrive/MyDrive/Fooocus-outputs\"  # @param {type:\"string\"}\n",
        "target_local_dir = \"/content/Fooocus/outputs\"\n",
        "\n",
        "# Google 出力ディレクトリを作成\n",
        "os.makedirs(target_local_dir, exist_ok=True)\n",
        "\n",
        "# オプションの設定\n",
        "use_japanese = True  # @param {type:\"boolean\"}\n",
        "model_type = \"anime\"  # @param [\"default\", \"anime\"] {allow-input: true}\n",
        "\n",
        "# 必要なパッケージのインストール\n",
        "!pip -qq install pygit2==1.15.1\n",
        "\n",
        "%cd /content\n",
        "!git clone https://github.com/lllyasviel/Fooocus.git\n",
        "# %cd /content/Fooocus\n",
        "# !python entry_with_update.py --share --always-high-vram\n",
        "\n",
        "# 日本語パッチを追加\n",
        "if use_japanese:\n",
        "    ja_json_url = \"https://raw.githubusercontent.com/aquapathos/FooocusJAni/refs/heads/main/ja.json\"\n",
        "    ja_json_path = \"/content/Fooocus/language/ja.json\"\n",
        "    os.makedirs(os.path.dirname(ja_json_path), exist_ok=True)\n",
        "    !curl -L -o {ja_json_path} {ja_json_url}\n",
        "    print(f\"ja.json downloaded and saved to {ja_json_path}\")\n",
        "\n",
        "# アニメ版の設定ファイルのパッチ(最新版)を追加\n",
        "if model_type == \"anime\":\n",
        "    anime_json_url = \"https://raw.githubusercontent.com/aquapathos/FooocusJAni/refs/heads/main/anime.json\"\n",
        "    anime_json_path = \"/content/Fooocus/presets/anime.json\"\n",
        "    os.makedirs(os.path.dirname(anime_json_path), exist_ok=True)\n",
        "    !curl -L -o {anime_json_path} {anime_json_url}\n",
        "    print(f\"anime.json downloaded and saved to {anime_json_path}\")\n",
        "\n",
        "%cd /content/Fooocus\n",
        "# Fooocus JP Script Options\n",
        "if model_type == \"default\" and not use_japanese:\n",
        "    !python entry_with_update.py  --always-high-vram  --output-path {target_drive_dir} --share\n",
        "elif model_type == \"default\" and use_japanese:\n",
        "    !python entry_with_update.py  --always-high-vram  --output-path {target_drive_dir} --share --language ja\n",
        "elif model_type == \"anime\" and not use_japanese:\n",
        "    !python entry_with_update.py --preset anime --always-high-vram --output-path {target_drive_dir} --share\n",
        "elif model_type == \"anime\" and use_japanese:\n",
        "    !python entry_with_update.py --preset anime --always-high-vram --output-path {target_drive_dir} --share --language ja"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "smqqaM5UI9zo"
      }
    }
  ]
}